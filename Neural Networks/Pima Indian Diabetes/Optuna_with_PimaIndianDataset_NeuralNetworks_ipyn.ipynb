{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f4dhG7hvhw5v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CNXkiXoCh-AH",
        "outputId": "ff485616-4e0f-415e-9ed6-8e4b3d2346a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   6  148  72  35    0  33.6  0.627  50  1\n",
              "0  1   85  66  29    0  26.6  0.351  31  0\n",
              "1  8  183  64   0    0  23.3  0.672  32  1\n",
              "2  1   89  66  23   94  28.1  0.167  21  0\n",
              "3  0  137  40  35  168  43.1  2.288  33  1\n",
              "4  5  116  74   0    0  25.6  0.201  30  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aa23cc1-6076-4468-8de0-2fad4016925d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>6</th>\n",
              "      <th>148</th>\n",
              "      <th>72</th>\n",
              "      <th>35</th>\n",
              "      <th>0</th>\n",
              "      <th>33.6</th>\n",
              "      <th>0.627</th>\n",
              "      <th>50</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aa23cc1-6076-4468-8de0-2fad4016925d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3aa23cc1-6076-4468-8de0-2fad4016925d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3aa23cc1-6076-4468-8de0-2fad4016925d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#load the csv file\n",
        "dataset = pd.read_csv('/content/diabetes_dataset.csv' , sep=',')\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boF8uSLai7sv",
        "outputId": "4a87cae7-3a1f-4f6a-a8f3-cc696e05aced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(767, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JEDUytcijgEm"
      },
      "outputs": [],
      "source": [
        "# Split the data into input X and output Y\n",
        "X = dataset.iloc[:, 0:8]\n",
        "Y = dataset.iloc[:,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LXj71XpKj0Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27795fba-2d69-4a8d-e832-b4269b13ed65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6  148  72  35    0  33.6  0.627  50\n",
            "0     1   85  66  29    0  26.6  0.351  31\n",
            "1     8  183  64   0    0  23.3  0.672  32\n",
            "2     1   89  66  23   94  28.1  0.167  21\n",
            "3     0  137  40  35  168  43.1  2.288  33\n",
            "4     5  116  74   0    0  25.6  0.201  30\n",
            "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
            "762  10  101  76  48  180  32.9  0.171  63\n",
            "763   2  122  70  27    0  36.8  0.340  27\n",
            "764   5  121  72  23  112  26.2  0.245  30\n",
            "765   1  126  60   0    0  30.1  0.349  47\n",
            "766   1   93  70  31    0  30.4  0.315  23\n",
            "\n",
            "[767 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u656V2eonKXq",
        "outputId": "ff70845d-2346-492f-e037-656a1fa11a6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      0\n",
            "1      1\n",
            "2      0\n",
            "3      1\n",
            "4      0\n",
            "      ..\n",
            "762    0\n",
            "763    0\n",
            "764    0\n",
            "765    1\n",
            "766    0\n",
            "Name: 1, Length: 767, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "FUL_KT2RnK2m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Keras Model\n",
        "model = Sequential([\n",
        "    Dense(units = 18, input_shape = (8,), activation = 'relu'),\n",
        "    Dense(units = 9, activation = 'relu'),\n",
        "    Dense(units = 1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "sSAdgV64oKyI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Keras Model\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "kiivb9l4o0UJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Keras Model\n",
        "model.fit(X, Y, epochs =150, batch_size = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhkprJt2prDq",
        "outputId": "6d04f320-b65c-4899-e411-7034527ef288"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 4.4806 - accuracy: 0.6402\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.9143 - accuracy: 0.6415\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8093 - accuracy: 0.6519\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7943 - accuracy: 0.6519\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.6597\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7107 - accuracy: 0.6688\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.6649\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.6675\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6610\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6714\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6806\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6832\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6793\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.7040\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6936\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6936\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6949\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.7066\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7066\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6949\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6923\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7001\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7093\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.7119\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7119\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7080\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7158\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.7145\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7223\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7119\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7184\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.7171\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7119\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.7093\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7158\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7210\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7210\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7184\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.7223\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7262\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7223\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7197\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7158\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7132\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7080\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.7236\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7158\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7327\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7236\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7262\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7314\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7223\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7327\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7301\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7262\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7262\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7405\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7223\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7249\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7327\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7262\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7366\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7301\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7327\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7379\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7471\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7432\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7405\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7275\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7445\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7405\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7419\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7432\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7549\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5326 - accuracy: 0.7549\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7432\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7405\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7497\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7379\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7379\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7471\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.7484\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7366\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7484\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7523\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7497\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7419\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7458\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7523\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7497\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7432\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7510\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7340\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7562\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7536\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7497\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7445\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7484\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7536\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7484\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7445\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7575\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7640\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7458\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7549\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7497\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7575\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7562\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7588\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7601\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.7510\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7445\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7549\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7614\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7458\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7419\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7640\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7497\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7601\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7523\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7497\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7549\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7692\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7575\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7718\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7640\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7640\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7718\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7497\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7614\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7705\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7692\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7823\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7705\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7575\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.7601\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7810\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7757\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7666\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7627\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7705\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7666\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7536\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7705\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7731\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7614\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7784\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7575\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7731\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7862\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcc7d185d80>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the keras model\n",
        "_, accuracy = model.evaluate(X,Y)\n",
        "print('Accuracy : %.2f'%(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxx0jknBr9l_",
        "outputId": "15058482-ba1e-4c19-ddce-1e4045b493d9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7901\n",
            "Accuracy : 79.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predicitions\n",
        "predictions = model.predict(X)\n",
        "#round predictions\n",
        "rounded =  [round(x[0]) for x in predictions]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qaxs6B6uJfG",
        "outputId": "c4e02dfa-e57d-44e0-b232-eb6669cc65df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class prediction\n",
        "prediction = (model.predict(X)>0.5).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VnzrASYu-ZF",
        "outputId": "3bac417d-3ccf-4469-b431-a8ccf18d6a24"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHe1hYYoW0Wm",
        "outputId": "8d186185-dc1a-4926-f841-06cffec863d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.6/390.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "zBjnxeRLXFSW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  #define hyperparameters to search\n",
        "  units = trial.suggest_loguniform('units', 8,20)\n",
        "  units2= trial.suggest_loguniform('units',8,20)\n",
        "  # train the model\n",
        "  model = Sequential([\n",
        "    Dense(units = units, input_shape = (8,), activation = 'relu'),\n",
        "    Dense(units = units2, activation = 'relu'),\n",
        "    Dense(units = 1, activation = 'sigmoid')\n",
        "    ])\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])\n",
        "  model.fit(X,Y, epochs = 150, batch_size = 10)\n",
        "\n",
        "  #make predictions on the test set and calculate accuracy\n",
        "  y_pred = model.predict(X)\n",
        "  auc_roc = roc_auc_score(Y, y_pred)\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "#Run Hyperparameter optimization with Optuna\n",
        "study = optuna.create_study(direction = 'minimize')\n",
        "study.optimize(objective, n_trials =150)\n",
        "\n",
        "#Train the model with the best hyperparamters found by Optuna\n",
        "best_params = study.best_params\n",
        "model = Sequential([\n",
        "    Dense(units = best_params['units'], input_shape = (8,), activation = 'relu'),\n",
        "    Dense(units = best_params['units2'], activation = 'relu'),\n",
        "    Dense(units = 1, activation = 'sigmoid')\n",
        "    ])\n",
        "model.fit(X,Y)\n",
        "\n",
        "#Make predictions on the test set and calculate accuracy\n",
        "y_pred = (model.predict(X)>0.5).astype(int)\n",
        "accuracy = accuracy_score(Y, y_pred)\n",
        "\n",
        "#print the best parameters\n",
        "print('Best Parameters: ', best_params)\n",
        "print('Accuracy : ',auc_roc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FxFD2RjnXT1C",
        "outputId": "ed33e06d-b99c-4eaf-e615-8264dcc6424d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-27 11:10:44,458] A new study created in memory with name: no-name-5d338de3-4914-487b-b884-e72809c4378f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-3a496f30997f>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units = trial.suggest_loguniform('units', 8,20)\n",
            "<ipython-input-32-3a496f30997f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units2= trial.suggest_loguniform('units',8,20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/77 [==============================] - 1s 2ms/step - loss: 22.8961 - accuracy: 0.6519\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 9.5386 - accuracy: 0.6519\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 2.7493 - accuracy: 0.5619\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.3084 - accuracy: 0.5189\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.9476 - accuracy: 0.5593\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8140 - accuracy: 0.6063\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7377 - accuracy: 0.6245\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.6336\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6735 - accuracy: 0.6454\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6597\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6662\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6675\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6623\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.6714\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.6884\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6780\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6044 - accuracy: 0.6949\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6767\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.6871\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.6949\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.6923\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.7040\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5932 - accuracy: 0.6897\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6910\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6923\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6910\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7093\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5942 - accuracy: 0.7014\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.7236\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7001\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7197\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.7119\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7158\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7001\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7106\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7145\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5693 - accuracy: 0.7171\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7236\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5725 - accuracy: 0.7027\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7288\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7314\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7275\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7171\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7184\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7197\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7145\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7262\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7327\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7301\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7275\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7158\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7353\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7432\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7314\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7327\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7223\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7366\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7392\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7301\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7262\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7288\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7445\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7405\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7340\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7340\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7327\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7392\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7458\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7327\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7353\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7314\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7497\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7432\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7249\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7353\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7536\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7314\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7366\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7432\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7523\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7379\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7549\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7471\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7419\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7458\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7379\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7562\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7484\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7366\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7497\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7379\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7432\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7523\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7432\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7392\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7510\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7392\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7419\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7392\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7614\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7549\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7510\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7575\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7392\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7549\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7419\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7523\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7458\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7445\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.7536\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7666\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7497\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7523\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7497\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7536\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7484\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7379\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7588\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7458\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7588\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7627\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7666\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7627\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7458\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7575\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7562\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7549\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7536\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7484\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7497\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7575\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7484\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7601\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7510\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7458\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7692\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7562\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7562\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7445\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7640\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7536\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7471\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7575\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7601\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7679\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7601\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7549\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7536\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7575\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7562\n",
            "24/24 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-27 11:11:09,585] Trial 0 finished with value: 0.7731420993804932 and parameters: {'units': 9.837957910838002}. Best is trial 0 with value: 0.7731420993804932.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-3a496f30997f>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units = trial.suggest_loguniform('units', 8,20)\n",
            "<ipython-input-32-3a496f30997f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units2= trial.suggest_loguniform('units',8,20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/77 [==============================] - 1s 2ms/step - loss: 1.5635 - accuracy: 0.5841\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6506\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6441\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7797 - accuracy: 0.6688\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.6910\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7402 - accuracy: 0.6636\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7475 - accuracy: 0.6858\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6806\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.7197\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6780\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.7053\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6427 - accuracy: 0.7158\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7145\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.7132\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.7210\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6704 - accuracy: 0.7053\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7379\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6030 - accuracy: 0.7184\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.7353\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7236\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7119\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.7262\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5929 - accuracy: 0.7171\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7197\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7392\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.7106\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7314\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7001\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7184\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.7392\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7510\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6080 - accuracy: 0.7340\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.7314\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7262\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7288\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.7458\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7419\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7562\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7392\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7340\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7249\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7340\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7353\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7275\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7405\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.7523\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7419\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7471\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7471\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7419\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7392\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7458\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7549\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7366\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7419\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7379\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7471\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7392\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7575\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7510\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7353\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7614\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7471\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7562\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7549\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7784\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7562\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.7588\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7588\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7627\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7549\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7471\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7497\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7510\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7705\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7575\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7627\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7510\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7640\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7849\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7471\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7614\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.7862\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7510\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7744\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7679\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7757\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7705\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7549\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7614\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7757\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7679\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7731\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7810\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7601\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7744\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7653\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7810\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7744\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7810\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7757\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7744\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7797\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7562\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7810\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7705\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7810\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7731\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7445\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7614\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7757\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7744\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7705\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7810\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7601\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7836\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7679\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7797\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7888\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7940\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7862\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7562\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7875\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7810\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7679\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7849\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7849\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7849\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7901\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7757\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7836\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7757\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7692\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7771\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7823\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7823\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7888\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7849\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7979\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7927\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.7784\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7927\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7953\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7757\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7966\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7823\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 1s 8ms/step - loss: 0.4508 - accuracy: 0.7979\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 1s 7ms/step - loss: 0.4620 - accuracy: 0.7927\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7940\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7914\n",
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-06-27 11:11:38,009] Trial 1 finished with value: 0.7731420993804932 and parameters: {'units': 18.439811092194105}. Best is trial 0 with value: 0.7731420993804932.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-3a496f30997f>:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units = trial.suggest_loguniform('units', 8,20)\n",
            "<ipython-input-32-3a496f30997f>:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  units2= trial.suggest_loguniform('units',8,20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/77 [==============================] - 1s 2ms/step - loss: 5.6873 - accuracy: 0.6180\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.2177 - accuracy: 0.6362\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.6610\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7919 - accuracy: 0.6362\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.6688\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6558\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6636\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.6688\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6169 - accuracy: 0.6714\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6767\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.6714\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6832\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7027\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6923\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.6884\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6949\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.7014\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7040\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6767\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6988\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5724 - accuracy: 0.7145\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7184\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.7066\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.7119\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6806\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7158\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7184\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.6949\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6910\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7014\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.7288\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7184\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7445\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7184\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7353\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7093\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7405\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7001\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7210\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7327\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7236\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.7066\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6066 - accuracy: 0.6832\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7458\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7314\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7014\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7497\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7432\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5699 - accuracy: 0.7314\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7314\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7392\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7445\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7184\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7405\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7340\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7210\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7379\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7405\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7301\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7484\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7392\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7366\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7340\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7471\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7405\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7405\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7392\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7392\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7405\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7405\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7379\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7575\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7484\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7640\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7471\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7197\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7432\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7601\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7588\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7340\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7627\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7510\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7588\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7588\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7849\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7575\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7536\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7340\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7575\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7679\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7536\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7536\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7562\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7432\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7353\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7614\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7705\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7432\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7471\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7627\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7575\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7497\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7536\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7562\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7575\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.5259 - accuracy: 0.7327\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7666\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7784\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7640\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7731\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7771\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7536\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7562\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7627\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7653\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7744\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7536\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7484\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7862\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7497\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7771\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7731\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7901\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7849\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7771\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7692\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7875\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7653\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7862\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7784\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7784\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7888\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7640\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7757\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7549\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7901\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7731\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7653\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7888\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7953\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7731\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7797\n",
            "Epoch 143/150\n",
            "15/77 [====>.........................] - ETA: 0s - loss: 0.4682 - accuracy: 0.7733"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2023-06-27 11:12:02,390] Trial 2 failed with parameters: {'units': 13.152904250779445} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-32-3a496f30997f>\", line 12, in objective\n",
            "    model.fit(X,Y, epochs = 150, batch_size = 10)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 894, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 926, in _call\n",
            "    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 143, in __call__\n",
            "    return concrete_function._call_flat(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1715, in _call_flat\n",
            "    if isinstance(arg, resource_variable_ops.BaseResourceVariable):\n",
            "  File \"/usr/lib/python3.10/abc.py\", line 119, in __instancecheck__\n",
            "    return _abc_instancecheck(cls, instance)\n",
            "KeyboardInterrupt\n",
            "[W 2023-06-27 11:12:02,405] Trial 2 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3a496f30997f>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#Run Hyperparameter optimization with Optuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#Train the model with the best hyperparamters found by Optuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-3a496f30997f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ])\n\u001b[1;32m     11\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m#make predictions on the test set and calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1713\u001b[0m     \u001b[0mvariables_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseResourceVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m         \u001b[0;31m# We can pass a variable more than once, and in this case we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;31m# pass its handle only once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}