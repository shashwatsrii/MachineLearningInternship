{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the liabraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from Model import neural_network\n",
    "from RandomInitialize import initialize\n",
    "from Prediction import predict\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('./mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Sun Mar 30 03:19:02 2014', '__version__': '1.0', '__globals__': [], 'mldata_descr_ordering': array([[array(['label'], dtype='<U5'), array(['data'], dtype='<U4')]],\n",
      "      dtype=object), 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'label': array([[0., 0., 0., ..., 9., 9., 9.]])}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from the data file.\n",
    "X = data['data']\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "# Since the data is in the image format, the pixes are in the range from 0-255\n",
    "# By dividing it by 255, I bring it to 0-1\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "Y = data['label']\n",
    "Y = Y.flatten()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000,) (14000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=0)\n",
    "print(X_train.shape,Y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "input_layer_size = 784 #since the images are 28x28 pixels .\n",
    "hidden_layer_size = 100\n",
    "num_labels = 10 #There are 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Initializing Thetas\n",
    "init_Theta1 = initialize(hidden_layer_size, input_layer_size)\n",
    "init_Theta2 = initialize(num_labels, hidden_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_nnparams = np.concatenate((init_Theta1.flatten(), init_Theta2.flatten()))\n",
    "maxiter = 100\n",
    "lambda_reg = 0.1  # To avoid overfitting\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, Y_train, lambda_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = minimize(neural_network, x0=init_nnparams, args=myargs,\n",
    "          options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac = True)\n",
    " \n",
    "nn_params = results[\"x\"]  # Trained Theta is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights are split back to Theta1, Theta2\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size* (input_layer_size+1)],(hidden_layer_size,input_layer_size+1))\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size* (input_layer_size+1):],(num_labels,hidden_layer_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 97.450000\n"
     ]
    }
   ],
   "source": [
    "# Predicting the accuracy of our model on the Test data\n",
    "m = X_test.shape[0]\n",
    "Xxx = X_test\n",
    "one_matrix = np.ones((m,1))\n",
    "Xxx = np.append(one_matrix, Xxx, axis = 1)\n",
    "z2 = np.dot(Xxx, Theta1.transpose())\n",
    "a2 = 1/(1+np.exp(-z2))\n",
    "one_matrix = np.ones((m,1))\n",
    "a2 = np.append(one_matrix,a2, axis = 1)\n",
    "z3 = np.dot(a2, Theta2.transpose())\n",
    "a3 = 1/(1+np.exp(-z3))\n",
    "p_test = (np.argmax(a3, axis = 1))\n",
    "pred_test = p_test\n",
    "print('Test Set Accuracy : {:f}'.format((np.mean(pred_test == Y_test)*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Accuracy : 99.428571\n"
     ]
    }
   ],
   "source": [
    "# Predicting the accuracy of our model on the Train data\n",
    "m = X_train.shape[0]\n",
    "Xx = X_train\n",
    "one_matrix = np.ones((m,1))\n",
    "Xx = np.append(one_matrix, Xx, axis = 1)\n",
    "z2 = np.dot(Xx, Theta1.transpose())\n",
    "a2 = 1/(1+np.exp(-z2))\n",
    "one_matrix = np.ones((m,1))\n",
    "a2 = np.append(one_matrix,a2, axis = 1)\n",
    "z3 = np.dot(a2, Theta2.transpose())\n",
    "a3 = 1/(1+np.exp(-z3))\n",
    "p_train = (np.argmax(a3, axis = 1))\n",
    "pred_train = p_train\n",
    "print('Train Set Accuracy : {:f}'.format((np.mean(pred_train == Y_train)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\MachineLearningInternship\\Neural Networks\\Hand Written Text Recognition\\HDR_ANN.ipynb Cell 19\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/MachineLearningInternship/Neural%20Networks/Hand%20Written%20Text%20Recognition/HDR_ANN.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m Path(\u001b[39m\"\u001b[39m\u001b[39m./image.jpeg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/MachineLearningInternship/Neural%20Networks/Hand%20Written%20Text%20Recognition/HDR_ANN.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mload_img(path , target_size \u001b[39m=\u001b[39m (\u001b[39m28\u001b[39m,\u001b[39m28\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/HP/OneDrive/Desktop/MachineLearningInternship/Neural%20Networks/Hand%20Written%20Text%20Recognition/HDR_ANN.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m image_array \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mimg_to_array(img)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./image.jpeg')\n",
    "image_array = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
