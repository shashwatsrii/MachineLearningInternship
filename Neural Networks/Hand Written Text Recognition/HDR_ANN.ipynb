{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the liabraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from Model import neural_network\n",
    "from RandomInitialize import initialize\n",
    "from Prediction import predict\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('./mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Sun Mar 30 03:19:02 2014', '__version__': '1.0', '__globals__': [], 'mldata_descr_ordering': array([[array(['label'], dtype='<U5'), array(['data'], dtype='<U4')]],\n",
      "      dtype=object), 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'label': array([[0., 0., 0., ..., 9., 9., 9.]])}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting features from the data file.\n",
    "X = data['data']\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "# Since the data is in the image format, the pixes are in the range from 0-255\n",
    "# By dividing it by 255, I bring it to 0-1\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "Y = data['label']\n",
    "Y = Y.flatten()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 784) (56000,) (14000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=0)\n",
    "print(X_train.shape,Y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "input_layer_size = 784 #since the images are 28x28 pixels .\n",
    "hidden_layer_size = 100\n",
    "num_labels = 10 #There are 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly Initializing Thetas\n",
    "init_Theta1 = initialize(hidden_layer_size, input_layer_size)\n",
    "init_Theta2 = initialize(num_labels, hidden_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_nnparams = np.concatenate((init_Theta1.flatten(), init_Theta2.flatten()))\n",
    "maxiter = 100\n",
    "lambda_reg = 0.1  # To avoid overfitting\n",
    "myargs = (input_layer_size, hidden_layer_size, num_labels, X_train, Y_train, lambda_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = minimize(neural_network, x0=init_nnparams, args=myargs,\n",
    "          options={'disp': True, 'maxiter': maxiter}, method=\"L-BFGS-B\", jac = True)\n",
    " \n",
    "nn_params = results[\"x\"]  # Trained Theta is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights are split back to Theta1, Theta2\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size* (input_layer_size+1)],(hidden_layer_size,input_layer_size+1))\n",
    "Theta2 = np.reshape(nn_params[hidden_layer_size* (input_layer_size+1):],(num_labels,hidden_layer_size+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy : 97.421429\n"
     ]
    }
   ],
   "source": [
    "test_pred = predict(Theta1, Theta2, X_test)\n",
    "print('Test Set Accuracy : {:f}'.format((np.mean(test_pred == Y_test)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Accuracy : 99.730357\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict(Theta1, Theta2, X_train)\n",
    "print('Train Set Accuracy : {:f}'.format((np.mean(train_pred == Y_train)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Thetas in .txt file\n",
    "np.savetxt('Theta1.txt', Theta1, delimiter=' ')\n",
    "np.savetxt('Theta2.txt', Theta2, delimiter=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "# from pathlib import Path\n",
    "# # import cv2\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading the image\n",
    "# img = cv2.imread(\"./image.png.png\")\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# image_resized = cv2.resize(img, (784,784))\n",
    "# print(image_resized.shape)\n",
    "# image_scaled = image_resized/255\n",
    "# print(image_scaled.shape)\n",
    "# image_in = image_scaled\n",
    "# print(image_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_x_out = np.reshape(image_in,[784,784])\n",
    "\n",
    "# #normalize the data\n",
    "# x_train_out = image_in.transpose()\n",
    "# print(x_train_out.shape)\n",
    "# # plt.imshow(image_scaled)\n",
    "# # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
